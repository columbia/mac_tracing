\section{Implementation}
We now discuss how we collect tracing events of interest.

\subsection{Tracing Tool}
Current MacOS systems support a system-wide tracing infrastructure built by Apple. [traces what]
By default, the infrastructure temporarily stores events in memory and flushes them to screen or disk when an internal buffer is filled.
We extended this infrastructure to support larger-scale tests without filling up the disk by implementing a ring buffer backed by a file.
We store at most 2GB of data [per log?], which corresponds to approximately XXX events (XXX time).

%Tracing infrastructure builtin current MacOS is lightweight event logging technology which collects system-wide information, stores temporarily in memory and flushes to screen or disk when the buffer is full.
%To support the 24X7 tracing without exhaust the system resource, we modify it to dump data to a ring buffer in a file.

\subsection{Instumentation}
Like Detour~\cite{detourXXXXXXXX}, we use static analysis to decide which instrumentation to perform, and then enact this instrumentation at runtime. 
On MacOS, most libraries as well as many of the applications used day-to-day are closed-source.
Adding tracing points to such code requires binary instrumentation.
Techniques such as library preloading to override individual functions are not applicable on MacOS, as libraries use two-level executable namespaces.
Hence, we implemented a binary instrumentation mechanism that allows developers to add tracing at any location in a binary image.

To add instrumentation, we insert 5-byte call instructions into the program. The user finds a location of interest in the code related to a specific event,
and we overwrite the victim instructions at that location. We create a new trampoline target function, whose first few instructions are those which were overwritten.
All of the trampoline functions are grouped together by our tool and a new library is generated.
This library provides the same public API as the original and is a drop-in replacement. We load and call the original code as an unmodified shared library.
The detours or trampoline calls are added by an initialization function in our new library; we temporarily mark the code region as writable with \texttt{mprotect}
to calculate offsets and perform the modifications. The initialization is called externally through \texttt{dispatch\_once}.
To use the modified libraries, we simply replace system libraries in their original locations (renaming them so that our code can access the originals).

One potential issue is that we use 5-byte call instructions with 32-bit displacements to jump from the original library to our new one.
This design requires that the libraries be loaded within +/- 2GB of each other in the 64-bit process address space.
However, since we list each original library as a dependency of our new libraries, the system loader will map each new and original library in sequence.
In practice, the libraries ended up very close to one another and we did not see the need to implement a more general long-jump mechanism.


%\begin{figure}
%    \begin{algorithmic}[1]
%        \Require {$VictimFuncs_{1} \dots VictimFuncs_{N}$ $VictimInstOffsets_{1} \dots VictimInstOffsets_{N}$ $ShellFuncPtrs_{1} \dots ShellFuncPtrs_{N}$}
%        \Procedure{init}{}
%        \For {$i \gets 1$ to $N$}
%        \State {$InstrVaddr$ $\gets$ {\textit{virtual addr of} $VictimFuncs_{i}$} + $VictimInstOffsets_{i}$}
%        \State {$Offset$ $\gets$ $InstrVaddr$ + 5 - $ShellFuncPtrs_{i}$}
%        \State {$CallqInstr$ $\gets$ \textit{callq} $Offset$}
%        \State $mprotect(page$ $of$ $InstrVaddr,$ $R|W|E)$
%        \State $memcpy(InstrVaddr,$ $CallqInstr)$
%        \State $mprotect(page$ $of$ $InstrVaddr, R|E)$
%        \EndFor
%        \EndProcedure
%    \end{algorithmic}
%    \label{fig:pseudo-code}
%    \caption{Pseudocode algorithm.}
%\end{figure}


\subsection{Hardware Watchpoint}
For any given shared variable of interest, we take advantage of hardware watchpoints.
Tracing points are recorded in the watchpoint handler when the variable is accessed.
We hook the handler in CoreFoundation to make sure that it is loaded correctly into the address space of our target application.
We set the hardware watchpoint in an ad-hoc manner with a custom command-line tool.
%Only the process id, the name, and size of the variable, operation type, read, write, execute, the watchpoint register id(from 0 to 3) need to be specified.

\subsection{Incremental Instrumentation}
Due to the transparent of programming paradigms designed by the developer, it does not always generate a complete and accurate dependency graph based on the builtin event schema.
The graph should be incrementally improved with new tracing points somehow.

%methodology
We built the toolkit upon the currently generated graph to guide the exploration of the over-connections and miss-connections of thread temporally.
Vouchers, which are propagated through the system to record if a process works on behalf of the other process, are also taken advantage of to check the false connections.
Threads connecting to multiple process are allowed only if their are vouchers reflecting their relationships.
Last but not least, checking the path of the connection, as well as the call stack provides hints on the graph improvements.

%results
In our experiment, we discovered multiple programming paradigms in the libraries that are not realized from the initial composing of the schema.
WindowServer will compact the request of send and receive in a mach\_msg\_overwrite\_trap system call, although they are on behalf of different userspace applications.
The function dispatch\_mig\_service, as well as the calling out functions in runloop, will finish works one by one in a loop without blocking between them.
This procedure to discover such programming paradigm can be repeated on regular executions before tracing for diagnosis.
On the contrary, the missing connections are much harder to explore.
As long as the remaining connections in the current graph help diagnosis, it is not necessary to explore.
