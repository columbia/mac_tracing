\section{Built-in Event Schema}\label{section: builtin_event_schema}
Our instrumentation framework must be able to capture system events that indicate a performance anomaly, without significantly impacting performance or consuming too much storage space.
The built-in event schema simplifies the use of our system for users without expert knowledge to capture application and system state.
Trace points and other messages that do not match the schema are discarded to save disk space.
We only record events that can be used to define execution segments within threads.
During post-processing, we form temporal links between threads, split some execution segments, and summarize the results for the user.
We make extensive use of the tracing points added by Apple and augment them with necessary attributes in the kernel.
Libraries and Frameworks are instrumented only when necessary.

Execution segments are defined in terms of links, so we discuss links next.

\subsection{Link}
We create link from source to destination thread in the following cases:
\begin{itemize}
        \item Inter-process Communications: As mentioned in pattern P7, MacOS
        IPC uses mach\_msg with up to four threads involved in every
        communication. Every step of the communication contains a reply port
        which can be used to trace the communication, and we create a link when
        the final thread sends a message to original reply port.

        \item Thread-scheduling: Thread context switches may occur in our logs
        for multiple reasons. Except for patterns P1 and P2, we create a link
        between the yielding thread and the thread that wakes up.

        \item Timer-arm-and-fire: Timers may be registered at any point by
        passing a function pointer to a system call \texttt{mk\_timer}. When
        the timer interrupt fires, the kernel will invoke each callback
        function. We link the callback to the original thread that armed the
        timer. If the timer re-registers itself (pattern P9), we will continue
        to link future callbacks to the original registration point.

        %\item Timer-arm-and-fire: Timers are widely used in the Cocoa
        %Framework. We add tracing points in the kernel to capture the where it
        %is armed and where it is fired or canceled. The timer mechanism is
        %implemented by encapsulating the callout function in a kernel object
        %and linking/removing the object to/from the timer lists. Therefore, we
        %record the slid address of the object and the user passed in function
        %address as attributes in the kernel, which is used to connect events of
        %timer armed, timer fired and timer cancellation.

        \item Dispatch Queue synchronization: Via tracing points, we link each enqueue,
        dequeue, and execution operation.

        \item Runloop synchronization: We wish to treat each event processed in
        a RunLoop as an independent execution segment. However, RunLoops
        frequently use complex control flow structures including sources,
        timers, and observers (pattern P8). We abstract these lower-level
        structures into single logical executions with appropriate links to
        source segments.

        \item CoreAnimation-set-and-display synchronization: Threads often
        create dependencies with the main thread through CoreAnimation render
        requests (pattern P4). If the user is concerned with any rendering
        bugs, these dependencies may be useful, so we create links---but for
        most cases, these links will not be helpful.

        \item Shared Variable: Threads can create implicit dependencies by
        synchronizing through shared variables. This case does not arise very
        frequently, but one example is in pattern P5. Such synchronizations
        will not be detected by our system unless explicit tracing is added for
        that variable. Once appropriate tracing points are added, we create
        links when one thread writes and another thread reads.

\end{itemize}

\subsection{Split}                                                                                                       
Continuously processing unrelated tasks is not uncommon in threads, from userspace, system services, and kernel threads.
Tracing points are required to split the events in a thread with the request boundary to exclude the false linkage in the graph.
With the boundary, the interleaving execution of requests on the same thread can be decomplexed, which benefit the following analysis when a comparison is required.
Three main categories are covered in our built-in schema.
    
\para{System interference}
User threads are randomly interrupted by the system activities, for example,
interrupts, timeshare maintenance. We recognize the boundary of them and
isolate them from activities triggered by a user application.

\para{Batch processing}
The second category is the batch processing in Daemons and Application
Services. Boundaries in this category are usually implied by certain
programming paradigms. A checking tool is created on our framework to unveil
these programming paradigms.

In our builtin schema, we cover not only the traditional programming model,
dispatch queue and run loops, but also recognize special ones. For example,
WindowServer sends out pending messages with the receiving of an unrelated
message from kernel via one system call, due to Apple's design of the port set.

Kernel thread is a important one who processes requests without boundaries.
While processing the timer, the kernel thread sends out messages one by one to
a list of user processes who armed timer before.

\para{Heuristics}
It is not always possible to manifest all programming paradigms before tracing.
In our framework, more can be added with heuristics by iteratively checking on
new data.

\subsection{Comprehension}
To make the output of our data more comprehensible, we add tracing points on system call and insert a lightweight call stack on demand.
\para{System calls}
We record the system call number and corresponding parameters. It helps to
understand what system service is required by the execution.

\para{Lightweight call stacks}
The user stacks are unwinded with the valid rbp in the system without
processing the complex jump instructions. It benefits the understanding of our
data with rare overhead.
