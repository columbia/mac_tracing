\section{Built-in Event Schema}\label{section: builtin_event_schema}
Our instrumentation framework must be able to capture system events that indicate a performance anomaly, without significantly impacting performance or consuming too much storage space.
The built-in event schema simplifies the use of our system for users without expert knowledge to capture application and system state.
Trace points and other messages that do not match the schema are discarded to save disk space.
We only record events that can be used to define execution segments within threads.
During post-processing, we form temporal links between threads and split execution into segments.
% and summarize the results for the user.
We make extensive use of the tracing points added by Apple and augment them with necessary attributes in the kernel.
Libraries and Frameworks are instrumented only when necessary.

Execution segments are defined in terms of links, so we discuss links next.

\subsection{Link}
We create link from source to destination thread in the following cases:
\begin{itemize}
        \item Inter-process Communications: As mentioned in pattern P7, MacOS
        IPC uses mach\_msg with up to four threads involved in every
        communication. Every step of the communication contains a reply port
        which can be used to trace the communication, and we create a link when
        the final thread sends a message to original reply port.

        \item Thread-scheduling: Thread context switches may occur in our logs
        for multiple reasons. Except for patterns P1 and P2, we create a link
        between the yielding thread and the thread that wakes up.

        \item Timer-arm-and-fire: Timers may be registered at any point by
        passing a function pointer to a system call \texttt{mk\_timer}. When
        the timer interrupt fires, the kernel will invoke each callback
        function. We link the callback to the original thread that armed the
        timer. If the timer re-registers itself (pattern P9), we will continue
        to link future callbacks to the original registration point.

        %\item Timer-arm-and-fire: Timers are widely used in the Cocoa
        %Framework. We add tracing points in the kernel to capture the where it
        %is armed and where it is fired or canceled. The timer mechanism is
        %implemented by encapsulating the callout function in a kernel object
        %and linking/removing the object to/from the timer lists. Therefore, we
        %record the slid address of the object and the user passed in function
        %address as attributes in the kernel, which is used to connect events of
        %timer armed, timer fired and timer cancellation.

        \item Dispatch Queue synchronization: Via tracing points, we link each enqueue,
        dequeue, and execution operation.

        \item Runloop synchronization: We wish to treat each event processed in
        a RunLoop as an independent execution segment. However, RunLoops
        frequently use complex control flow structures including sources,
        timers, and observers (pattern P8). We abstract these lower-level
        structures into single logical executions with appropriate links to
        source segments.

        \item CoreAnimation-set-and-display synchronization: Threads often
        create dependencies with the main thread through CoreAnimation render
        requests (pattern P4). If the user is concerned with any rendering
        bugs, these dependencies may be useful, so we create links---but for
        most cases, these links will not be helpful.

        \item Shared Variable: Threads can create implicit dependencies by
        synchronizing through shared variables. This case does not arise very
        frequently, but one example is in pattern P5. Such synchronizations
        will not be detected by our system unless explicit tracing is added for
        that variable. Once appropriate tracing points are added, we create
        links when one thread writes and another thread reads.

\end{itemize}

\subsection{Split}                                                                                                       
After forming links, we split tracing events in the thread log into execution
segments, which represents a series of operations tied to a specific logical
event:

%Continuously processing unrelated tasks is not uncommon in threads, from
%userspace, system services, and kernel threads. Tracing points are required to
%split the events in a thread with the request boundary to exclude the false
%linkage in the graph. With the boundary, the interleaving execution of requests
%on the same thread can be decomplexed, which benefit the following analysis
%when a comparison is required. Three main categories are covered in our
%built-in schema.
\begin{itemize}
        \item Context Switches: User space thread code is frequently context
switched out, e,g for signal handling (pattern P1) and timeshare maintainence
(pattern P2). Whenever it happens, we isolate the code runs on different thread
context by splitting before and after the context switch.
        \item Sequential Processing: Many builtin control structures, such as
RunLoop and Dispatch Queue, process events one after another. We assume each
event is independent and split accordingly.
        \item Batch Processing: In pattern P3 and P6, the processing of
multiple events is interleaved. For example, WindowServer combines sending and
receiving messages from independent events into a single system call. We split
the operations into two execution segments. 

%\item User specified programming paradigms
%It is not always possible to manifest all programming paradigms before tracing.
%In our framework, more can be added with heuristics by iteratively checking on
%new data.
\end{itemize}

%\subsection{Comprehension}
%\subsection{Segment Identification}
%summarize the results for the user.
%To make the output of our data more comprehensible, we add tracing points on system call and insert a lightweight call stack on demand.
%\para{System calls}
%We record the system call number and corresponding parameters. It helps to
%understand what system service is required by the execution.
%
%\para{Lightweight call stacks}
%The user stacks are unwinded with the valid rbp in the system without
%processing the complex jump instructions. It benefits the understanding of our
%data with rare overhead.
