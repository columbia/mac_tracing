\section{Overview}\label{sec:overview}

\subsection{Argus Work Flow}
\begin{figure}[tb]
    \centering
    \input{figures/overview_tikz.tex}
    \caption{\xxx Work Flow}
    \label{fig:argus-overview}
\end{figure}

In this section, we describe the steps a user takes to investigate a performance
anomaly with \xxx. Figure~\ref{fig:argus-overview} shows \xxx's work flow, which
consists of two phases. A user runs command ``\vv{\xxx start}'' to enter the
system-wide tracing phase, within which \xxx logs events as listed in Table
~\ref{table:event_types} (\S\ref{subsec:eventgraph}). Whenever a user detects
a performance issue such as a spinning cursor, she runs ``\vv{\xxx debug}'' to
enter the diagnosis phase.

%%In the cases we consider, the flow of information across threads and processes
%%is essential to discovering the system state that leads to a performance bug.
%%\xxx recovers UI actions from logged data rather than being told the actions
%%that a user performs, because not all of them may be relevant to the true bug.

Central to our system is our \emph{event graph}, a generalized control-flow
graph which includes inter-thread and inter-process dependencies. Diagnosis
and inferences are performed within this graph, in a semi-automated fashion:
\xxx performs searches and subgraph matching to trace logical events as they
flow through the system, and the user can interactively query this graph to
understand the problem or provide guidance to \xxx. The event graph is described
in further detail in \S\ref{subsec:eventgraph}. Next, we describe the graph
operations \xxx performs leading to a diagnosis.

\subsection{Diagnosis with Graph}\label{subsec:debug}

\begin{algorithm}[ht!]
    \caption{Main \xxx algorithm.}
    \label{alg:alg-main}
\begin{algorithmic}[1]
\Require{Program to run + buggy test case
			+ (optional) similar baseline test case}
\Ensure{Sequence of UI events triggered the performance problem 
		+ Nodes from Event Graph}
\Statex
\Function{\xxx Main}{}
\State {$TracingEvents$ $\gets$ Run program under \xxx,
		trigger baseline case (if possible) and buggy test case}\label{algmain:collectdata}
\State {$HeuristicsSet$ $\gets$ $\{default$ $ $ $heuristics\}$}
\State {$EventGraph$ $\gets$ ComputeGraph($HeuristicsSet$, $TracingEvents$)}
\label{algmain:recompute}
\State {$SpinningNode$ $\gets$ search $EventGraph$}\label{algmain:findspinningnode}
\If {$SpinningNode$ $==$ $CPU busy execution(livelock)$}
	\State{run backward traversal of main thread until UI event found}\label{algmain:1st}
\Else
	\State{$N_0$ $\gets$ $SpinningNode$}\label{algmain:2and3begin}
	\State{$N_1$ $\gets$ FindSimilarNode($EventGraph$, $N_0$)}
	\State{call AssistedGraphDiff($EventGraph$, $N_0$, $N_1$)}
	\If {new\_hueristics were added}
		\State \Goto{algmain:recompute}
	\EndIf\label{algmain:2and3end}
\EndIf
\State{Return set of UI events and root cause related Nodes}
\EndFunction
\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:alg-main} shows how \xxx investigates a performance anomaly
for users, given a buggy test case and (potentially) a baseline test case
for comparison purposes. We assume the user has a program to execute and a
buggy test case that can be reproduced eventually; the tracing log collected
by \xxx would contain a similar event processing normally, or the user can
provide a normally executed test case for comparison purpose, listed in
line~\ref{algmain:collectdata}. \xxx initializes this debugging phase by
constructing an event graph from all logged events up to user-specified duration
in line~\ref{algmain:recompute}. The detail of algorithm ComputeGraph is
presented in Algorithm ~\ref{alg:graphcomputing}(\S\ref{subsec:graphcomputing}).

The exact searches and queries performed on the graph depend on the bug under
investigation. Consider a common performance bug on macOS, the \emph{spinning
cursor}, which indicates the current application's main thread has not processed
any UI events for over two seconds. \xxx queries the event graph to find the
ongoing event in the application's main thread concurrent to the display of
the spinning cursor shown in line~\ref{algmain:findspinningnode}. Upon examining
what the main thread is actually doing, the user may encounter three potential
cases. First, the thread may be busy performing lengthy CPU operations (which
take longer than two seconds). Second, the thread may be in a blocking wait.
Third, the main thread may be in a yield loop, which is highly indicative
it is waiting on a data flag (\eg, ``while(!done) thread\_switch();'').
Line ~\ref{algmain:1st} to ~\ref{algmain:2and3end} is to track events and
synchronization primitives throughout the system to figure out the root cause,
in terms of user input events and bug in code, for the three cases.

For the first case, shown in line~\ref{algmain:1st}, \xxx will examine
the stack trace and find a sequence of events that led to the current CPU
processing. If more specific tracing is required, the user can rerun the
program with more heavyweight instrumentation enabled for any portion of the
code's execution, gathering a precise sequence of calls or even instructions
executed.

On the contrary, \xxx locates the node $N_1$ for the rest
cases, either a blocking wait or a yield loop, in our graph
when the spinning beachball is triggered, as is shown between
line~\ref{algmain:2and3begin} and line~\ref{algmain:2and3end}. Then \xxx applies
Algorithm~\ref{alg:alg-findsimilarnode} to locate a node $N_0$ in our graph that
corresponds to the baseline version of the hanging node $N_1$.

For the second case of block waiting, \xxx takes the assumption there usually
exits a chain of blocking thread and the initial blocking thread is the most
valuable for debugging. Consequently, \xxx diffs the subgraphs between the
blocking version and the baseline version to determine their difference with
Algorithm ~\ref{alg:alg-graphdiff}.

In the third case, the main thread is in a yield loop, which is highly indicative it is
waiting on a data flag (\eg, ``while(!done) thread\_switch();''). To discover
a data flag, the user re-runs the application with \xxx to collect instruction
traces of the concurrent event in both the normal and spinning cases and detects
where the control flow diverges. She then reruns the application with \xxx to
collect register values for the basic blocks before the divergence and uncovers
the address of the data flag. She then configures \xxx to log accesses to the
flag during system-wide tracing. Finally, she can recursively apply \xxx to
further diagnose ``the culprit of the culprit''.

Based on our results and experience, the first case is the most common, but
the second and third represent more severe bugs. Long-running CPU operations
tend to be more straightforward to diagnose with existing tools. Blocking
or yielding cases involve multiple threads and processes, and are extremely
hard to understand and fix even for the application's original developers.
Therefore, issues remain unaddressed for years and significantly impact the user
experience. Algorithm~\ref{alg:alg-main} is semi-automated but can integrate
user input at each stage to leverage hypotheses or expert knowledge as to why a
hang may occur.

\begin{algorithm}[ht!]
    \caption{\xxx Find similar node algorithm.}
    \label{alg:alg-findsimilarnode}
\begin{algorithmic}[1]
%%  Output: Similar node set
\Require{EventTypesSet + SpinningNode + Graph}
\Ensure{SimilarNodeSet}
\Statex
\Function{FindSimilarNode}{}
\State{$thread$ $\gets$ thread of $Node_blocking$}
\For {$Node_i$ in $thread$ other than $Node_blocking$}
	\State{$iter_i$ $\gets$ iterator of first event in $Node_i$}
	\State{$iter_b$ $\gets$ iterator of first event in $Node_blocking$}
	\While {$iter_b$ $\ne$ end \And $iter_i$ $\ne$ end}
		\While {$iter_i$ $\ne$ end \And $Event$($iter_i$) $\notin$ $EventTypesSet$}
			\State{$iter_i$++}
		\EndWhile
		\While {$iter_b$ $\ne$ end \And $Event$($iter_b$) $\notin$ $EventTypesSet$}
			\State{$iter_b$++}
		\EndWhile
		\If {$iter_b$ $\neq$ end \And $iter_i$ $\neq$ end}
			\State{$if_eq$ $\gets$ CompareEvent($Event$($iter_b$), $Event$($iter_i$))}
			\If {$if_eq$ $==$ False}
				\State{Break}
			\EndIf
		\EndIf
	\EndWhile
	\If {$iter_b$ $==$ end \And $iter_i$ $==$ end}
		\If {wresult of $Node_i$) $\neq$ wresult of $Node_blocking$
		\Or timespan of $Node_blocking$ - timespan of $Node_i$ $\geq$ threshhold}
			\State{Put Node into $SimilarNodeSet$}
		\EndIf
	\EndIf
\EndFor
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[ht!]
    \caption{\xxx Assisted graph diff algorithm.}
    \label{alg:alg-graphdiff}
\begin{algorithmic}[1]
\Require{SpinningNode + BaselineNode + Graph}
\Ensure{Possible root cause of thread blocking}
\Statex
\Function{AssistedGraphDiff}{}
\State{$ResultSet$ $\gets$ $\{\}$}
\State{$SlicingPath$ $\gets$ BackwardSlicing on $BaseLineNode$}
\State{$T_spinning$ $\gets$ timestamp of spinning beachball for $SpinningNode$}
\For{$thread$ $\gets$ thread of $Node_i$ in $SlicingPath$}
	\State{$T_normal$ $\gets$ timestamp of last event in $Node_i$}
	\State{$Node_blocking$ $\gets$ $thread$ blocks during ($T_normal$, $T_spinning$)}
	\If {$Nodeblocking$  $\neq$ $NULL$}
		\State{put $Node_blocking$ into $ResultSet$}
	\EndIf
	\If {$UI Events$ in Main UI thread}
		\State{put $UI Event$ into $ResultSet$}
	\EndIf
\EndFor
\State{Return $ResultSet$}
\EndFunction
\end{algorithmic}
\end{algorithm}


\subsection{\xxx Assisting Algorithm}

We mentioned previously in \S\ref{subsec:debug} that \xxx explores the event
graph semi-automatically to narrow in on relevant nodes in event graph for
diagnosis. Algorithms that require no user intervention are described
in this section.

\paragraph{Find Similar Node Algorithm}

FindSimilarNode in Algorithm~\ref{alg:alg-findsimilarnode} is meant to find
nodes which have the same high level semantics but different execution results
compared to the spinning node. For example, both of them are waiting on locks,
but one returns successfully and the other not. \xxx defines a subset of events
that preserve semantics, which contains System\_call, Back\_trace, NSApp\_event,
Mach\_message, Wait, Dispatch\_enqueue, Dispatch\_invoke, Runloop\_submit,
Runloop\_invoke, Share\_flag\_read and Share\_flag\_write. The comparison of
events depends on event type and its category in Table~\ref{table:event_types}.
For connection events, \xxx compares their peers. For semantics Events, \xxx
compares the content of the event attributes, for example, the system call
number. The wait results of wait event usually differentiate the normal
execution and buggy case. \xxx differentiate the cases with wait results by
default. Depending on the report detail of the spinning node, user can change
the comparing metrics or request \xxx to compare proceeding nodes to narrow down
the result set reported.

\paragraph{Graph Diff Algorithm}

\xxx tries to figure out the root cause for the second
case(\S\ref{subsec:debug}) with Algorithm~\ref{alg:alg-graphdiff}. \xxx assumes
that the blocking in the main thread usually caused by the unresponsive of
another thread. In the algorithm, with the input of the blocking node in main
thread, \xxx carries out a backward path slicing from the node from the baseline
case in the graph. The path consists of nodes from multiple threads. \xxx
traverses every thread and confines the search within the time interval from the
base line node in the thread and the timestamp when the blocking node appears
in main thread. Among them \xxx expects to find a potential blocking in some
threads and reports them. At the same time \xxx also collects the UIEvents into
return set.

\subsection{Chromium Spinning Cursor Example}

%   resolve symbol, save to log
%     search for set\_spinning
%     if found,
%       find main thread node at the time of set\_spinning
%     find fontd
%     manually check nodes in each thread immediately after the nodes in the slice (normal abnormal boundary)
%  output is a node, and a HTML dump of node and immediate predecessors and successors
% systems preference          
%  spinning node in UI thread is not waiting
%  so we look for messages, and find the diff

One of the authors experienced first-hand the aforementioned performance issue
in Chromium, an open-source browser engine that powers Google Chrome and,
starting recently, Microsoft Edge~\cite{chromiumurl}.  She tried to type in the
Chromium search box a Chinese word using SCIM, the default Chinese Input Method
Editor that ships with MacOS.  The browser appeared frozen and the spinning
cursor occurs for a few seconds.  Afterwards everything went back to normal.
This issue is reproducible and always ruins her experience, but it is quite
challenging to diagnose because two applications Chromium and SCIM and many
daemons ran and exchanged messages.  This issue was reported by other users for
other non-English input methods, too.

To diagnose this issue with \xxx, the author started system-wide tracing, and
then reproduced the spinning cursor with a Chinese search string typed via SCIM
while the page was loading. It produced normal cases for the very first few
characters, and the browser got blocked with the rest input as spinning cases.
The entire session took roughly five minutes.

She then ran \xxx to construct the event graph. The graph had 2,749,628 vertexes
and 3,606,657 edges, almost fully connected. It spans across 17 applications;
109 daemons including \vv{fontd}, \vv{mdworker}, \vv{nsurlsessiond} and
helper tools by applications; 126 processes; 679 threads, and 829,287
IPC messages. Given the scale of the graph and the diverse communication
patterns, it would be extremely challenging for prior automated causal tracing
tools~\cite{aguilera2003performance, zhang2013panappticon, attariyan2012x,
cohen2004correlating} because they handle a fairly limited set of patterns.
Tools that require manual schema~\cite{barham2004using, reynolds2006pip}, would
be prohibitive because developers would have to provide schema for all involved
applications and daemons.

Next she ran \xxx to find the spinning node in the main thread of the browser
process. \xxx returned a \vv{Wait} event on condition variable with timeout that
blocked the main thread for a few seconds. Thus \xxx compares the spinning node
to a similar one in normal case where the \vv{Wait} was signaled quickly with
Algorithm~\ref{alg:alg-findsimilarnode}. \xxx reported three, and confirmed with
the user which one she wanted.

\xxx then found the normal-case wake-up path which connects five threads. The
browser main thread was signaled by a browser worker thread, which received IPC
from a worker thread of \vv{renderer} where the rendering view and WebKit code
run. The worker thread is woken up by the \vv{renderer} main thread, which in
turn woken by fontd, the font service daemon. \xxx further compared the wake-up
path with the spinning case with the Algorithm ~\ref{alg:alg-graphdiff}, and
returned the \vv{wait} event on semaphore in the \vv{renderer} main thread, the
culprit that delayed waking up the browser main thread over 4 seconds.

What caused the wait in the \vv{renderer} main thread though? She thus continued
diagnosis and recursively applied \xxx to the wait in \vv{renderer}, and got
the wake-up path. The culprit that delayed the semaphore was the timeouts in
the browser's main thread. At this point, a circular wait formed. To understand
what exactly happens in the situation, she inspected the full call stacks by
\xxx scripts, taking the reported nodes from the renderer and the browser as
input. Inspection reveals that the \vv{renderer} requested the browser's help to
render Javascript and waited for reply with semaphore. The browser was waiting
for the \vv{renderer} to return the string bounding box and the \vv{renderer}
was waiting for the browser to help render Javascript. This circular wait was
broken by a timeout in the browser main thread (the \vv{wait} on cv timeout was
1,500 ms). While the system was able to make progress, the next key press caused
the spinning cursor to display for another 1,500 ms. The timeout essentially
converted a deadlock into a livelock.

The finding was verified with chromium source code. Shortening the timeout interval
in the main browser thread proportionally shortens the waiting of the main
render thread on processing the javascript. Skipping certain javascripts
processing in the renderer thread cuts down the success rate of spinning case
reproducing.

%%Next she ran \xxx to find the event in the main thread of the browser process.
%%\xxx returned a \vv{cv\_timed\_wait} event %(Figure~\ref{fig:chromium-trace})
%%that blocked the main thread for a few seconds. Inspection of the
%%lightweight call stack revealed that this wait happened within a call to
%%\vv{TextInputClientMac::GetFirstRectForRange}. Without knowing the application's
%%semantics, she could not understand this method. Thus she ran \xxx to compare
%%the spinning case to a normal case. \xxx searched in the main thread of the
%%browser process for vertexes similar to this wait waiting vertexes similar to
%%this wait, found three, and confirmed with the user which one she wanted.
%%
%%\begin{figure*}[p]
%%    \centering
%%	\input{figures/chromium_case_study_tikz.tex} 
%%    \caption{Chromium case study.}
%%    \label{fig:chromium-trace}
%%\end{figure*}
%%%need to adjust based on the new figure
%%\xxx then found the normal-case wake-up path shown in the figure, which
%%connects five threads.  The browser main thread was signaled by a browser
%%worker thread as shown in step \textcircled{1} of backward slicing in Figure
%%\ref{fig:chromium-trace}, which in turn \vv{read\_file} in step \textcircled{2}
%%for IPC from a worker thread of \vv{renderer}, the daemon for rendering screens.
%%The \vv{renderer} worker thread is woken up by the \vv{renderer} main thread to
%%\vv{read\_file} \textcircled{3}, which in turn \vv{recv\_msg} \textcircled{4}
%%from \vv{fontd}, the font service daemon.  From this path, we could guess that
%%\vv{GetFirstRectForRange} was for the browser to understand the bounding box of
%%the search string.  \xxx further compared the wake-up path with the spinning
%%case, and returned the \vv{wait\_semaphore} event in the \vv{renderer} main
%%thread, the culprit that delayed waking up the browser main thread over 4
%%seconds.

%%What caused the wait in the \vv{renderer} main thread though?  She thus
%%continued diagnosis and recursively applied \xxx to the wait in \vv{renderer},
%%and got the wake-up path shown in the figure for this wait.  Inspection reveal
%%that the \vv{renderer} requested the browser's help to render Javascript and was
%%waiting for a reply.  At this point, a circular wait formed because the browser
%%was waiting for the \vv{renderer} to return the string bounding box and the
%%\vv{renderer} was waiting for the browser to help render Javascript.  This
%%circular wait was broken by a timeout in the browser main thread (the
%%\vv{cv\_timed\_wait} timeout was 1,500 ms).  While the system was able to make
%%progress, the next key press caused the spinning cursor to display for another
%%1,500 ms.  The timeout essentially converted a deadlock into a livelock.