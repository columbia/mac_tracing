\section{Implementation}\label{sec:implementation}

In this section, we discuss how \xxx collects tracing events from both kernel
and libraries, and user interactions which \xxx leverages to ease diagnosis.

\subsection{Event Tracing}
Current macOS systems support a system-wide tracing infrastructure built by
Apple~\cite{linktotracetool}. By default, the infrastructure temporarily stores
events in memory and flushes them to screen or disk when an internal buffer is
filled. We extended this infrastructure to support larger-scale tests and avoid
filling up the disk with a file-backed ring buffer. Each log file is 2GB by
default, which users can override. This size corresponds corresponds to
approximately 19 million events (about 5 minutes with normal operations).

The default tracing points in macOS provide too limited information to enact
causal tracing. As a result, we instrument both the
kernel~\cite{linkofxnusourcecode} (at the source level) and key libraries (at
the binary level), to gather more tracing data. We instrumented the kernel with
1,193 lines of code, and binary-instrumented the following libraries:
\vv{libsystem\_kernel.dylib}, \vv{libdispatch.dylib}, \vv{libpthread.dylib},
\vv{CoreFoundation}, \vv{CoreGraphics}, \vv{HIToolbox}, \vv{AppKit} and
\vv{QuartzCore} in \nlibchanges different places. 

%%Next subsection describes our binary instrumentation tool


\subsection{Instrumentation}

Most libraries as well as many of the applications used day-to-day are
closed-source in macOS. To add tracing points to such code, techniques such as
library preloading to override individual functions are not applicable on macOS,
as libraries use two-level executable namespace~\cite{twolayernamespace}. Hence,
we implemented a binary instrumentation mechanism that allows developers to add
tracing at any location in a binary image.

Like Detour~\cite{hunt1999detours}, we use static analysis to decide which
instrumentation to perform, and then enact this instrumentation at runtime.
Firstly, the user finds a location of interest in the image related to a
specific event by searching a sequence of instructions. Then the user replaces a
call instruction to invoke a trampoline target function, in which we overwrite
the victimized instructions and produce tracing data with API from Apple.
All of the trampoline functions are grouped into a new image, as well as an
initialization function which carries out the drop-in replacement. Then command
tools from \xxx helps to configure the image with the following steps: (1)
re-export all symbols from the original image so that the original code can be
called like an shared library; (2) rename the original image, and use original
name for the new one to ensure the modifications are properly loaded; (3) invoke
the initialization function externally through \texttt{dispatch\_once} during
the loading.

%%One potential issue is that we use 5-byte call instructions with 32-bit
%%displacements to jump from the original library to our new one.  This design
%%requires that the libraries be loaded within +/- 2GB of each other in the
%%64-bit process address space.  However, since we list each original library as
%%a dependency of our new libraries, the system loader will map each new and
%%original library in sequence.  In practice, the libraries ended up very close
%%to one another and we did not see the need to implement a more general
%%long-jump mechanism.

%\subsection{User Interaction}\label{subsec:tcp}
%\para{Tracing Custom Primitives}

\subsection{Tracing Data Flags} \label{subsec:tcp}
%%XXX give a simple command line example of how a user can ask \xxx to trace a
%%data flag
%%XXX say what we do in watch point exception handler (record instruction so
%%can determine read or write, and reg values)
As described in (\S\ref{sec:inaccuracy}), under-connection due
to the missing data dependency requires users' interaction.
Users specify that reads and writes to a given global variable should be considered data dependencies.
Global-variable tracing is possible through \xxx's binary rewriting, but we also provide a
simple command line tool which uses watchpoint registers to record
\dataflagwrite and \dataflagread events. The tool takes as input the process ID,
path to the relevant binary image, and the symbol name of the global variable. Here is
a simple example of how a user would ask \xxx to trace \vv{\_gOutMsgPending}:

\begin{lstlisting}
./breakpoint_watch Pid/of/WindowServer Path/to/CoreGraphics \
	_gOutMsgPending
\end{lstlisting}

At load time, \xxx hooks the watchpoint break handler in CoreFoundation to
make sure that it is loaded correctly into the address space of our target
application. The handler invokes Apple's event tracing API to record the value
of the data flag and the operation type (read or write).

\subsection{Tracing Instructions and Calls}

Users may need to gather more information, such as individual instructions and
call stacks, to come up with and verify a binary patch. \xxx integrates with
\vv{lldb} to capture this information and add it to the corresponding vertices
in the event graph.

We gather call stacks only at relevant locations, to reduce the data collection
overhead. Our \vv{lldb} scripts go through the instructions of apps and
frameworks step by step to capture the parameters tainted by user inputs. Only
at each beginning of a function call does the script record a full call stack.
We also step over and record the return value of APIs from low-level libraries
(i.e. those with the filename extension \vv{.dylib}).

The combination of instruction-level tracing and occasional call-stacks offers
more than enough detail to diagnose even the most arcane issues, and in our
experience has been very helpful in multiple steps of an \xxx diagnosis.

\subsection{Find Baseline Scenario}

\xxx leverages a baseline scenario to discover missing wake-up edges in
\textbf{Long Wait} cases. 

The baseline scenario is identified from the vertexes which share the same
high level semantics as the \spinningnode, but exposes different execution
results. \xxx recognizes high level semantics of vertices with semantic
events, including system calls, call stacks, user actions. Their sequential
order and runtime unrelated attributes are treated as hallmarks. For example,
\xxx compares vertices with system call numbers and symbol names in call stacks.
To improve the accuracy, \xxx also checks the events forming edges, including
messages, dispatch queue operations, runloop operations, \dataflagread and
\dataflagwrite, as they might reflect the low-level behaviors of developers'
intent. More over, a user can also instruct \xxx to inspect proceeding vertices
for accuracy purpose. By default, \xxx discriminate the execution results with
the time cost and wait results.

If multiple \similarnode are identified, \xxx usually asks users for a
confirmation, or choose the most recent one heuristically.
