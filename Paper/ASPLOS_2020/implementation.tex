\section{Implementation}\label{sec:implementation}
We now discuss how we collect tracing events from both kernel and libraries.

\subsection{Event Tracing}
Current MacOS systems support a system-wide tracing infrastructure built by
Apple XXX~\ref{linktotracetool}. By default, the infrastructure temporarily stores
events in memory and flushes them to screen or disk when an internal buffer is
filled. We extended this infrastructure to support larger-scale tests and avoid
filling up the disk with a file-backed ring buffer. Subject to configurarion,
it allows at most 2GB of data per log, which corresponds to approximately
18,560,187 events (about 5 minute with normal operations).

The default tracing points in MacOS provide too limited information to
apply causual tracing. As a result, we both patch source code of kernel
XXX~\ref{linkofxnusourcecode} and binary instrument libraries to gether
more tracing data. In \xxx, we patched the kernel with 1193 lines of
code, and instrumented the libraries including: libsystem\_kernel.dylib,
libdispatch.dylib, libpthread.dylib, CoreFoundation, CoreGraphics, HIToolbox,
AppKit and QuartzCore, with our binary instrumentation.

\subsection{Instrumentation}
Most libraries as well as many of the applications used day-to-day are
closed-source in MacOS. To add tracing points to such code, techniques such as
library preloading to override individual functions are not applicable on MacOS,
as libraries use two-level executable namespaces~\cite{}. Hence, we implemented
a binary instrumentation mechanism that allows developers to add tracing at
any location in a binary image. Like Detour~\cite{hunt1999detours}, we use
static analysis to decide which instrumentation to perform, and then enact this
instrumentation at runtime.

Now we talk about our instrumentation mechanism. Firstly, users find a location
of interest in the image related to a specific event by searching a sequence of
instructions. Then the users replace a call instruction to invokes a trampoline
target function, in which we overwrite the victimed instructions and produce
tracing data with API from Apple. All of the trampoline functions are grouped
into a new image, as well as an initialization function which carries out the
drop-in replacement. Then command tools from \xxx helps to configure the image
with the following steps: (1)re-export all symbols from the original image so
that the original code can be called Like an shared library; (2)replace the
original image with the new one by renaming them to ensure the modifications
are properly loaded; (3)invoke the initialization function externally through
\texttt{dispatch\_once} during the loading.

%%One potential issue is that we use 5-byte call instructions with 32-bit
%%displacements to jump from the original library to our new one.  This design
%%requires that the libraries be loaded within +/- 2GB of each other in the
%%64-bit process address space.  However, since we list each original library as
%%a dependency of our new libraries, the system loader will map each new and
%%original library in sequence.  In practice, the libraries ended up very close
%%to one another and we did not see the need to implement a more general
%%long-jump mechanism.

\subsection{User Interaction} 
\subsubsection{Tracing Custom Primitives} \label{subsec:tcp}\hfill\\
%%XXX give a simple command line example of how a user can ask \xxx to trace a
%%data flag
%%XXX say what we do in watch point exception handler (record instruction so
%%can determine read or write, and reg values)

As described in (\S\ref{subsec:userinteraction}), under-connection due
to the missing share data dependency requires users'interaction. \xxx
provides a command line tool which sets the watch point registers to record
share\_flag\_write and share\_flag\_read events in ad-hoc manner. This is one
way users can easily collect the tracing events, and the more tech-savvy users
can also instrument the binary. The tool takes the process id, path to image
where the variable is defined and the symbol of the variable as input. We
show the simple example how a user ask \xxx to trace \_gOutMsgPending in the
following command.

\begin{BVerbatim}
./bp_watch pidofWindowServer \
	Path/to/CoreGraphics _gOutMsgPending
\end{BVerbatim}

\xxx hooks the watch point break handler in CoreFoundation to make sure that it is
loaded correctly into the address space of our target application. The handler
invokes the event tracing API from Apple to record the value of the shared
variable and the operation type: read or write.
\\
\subsubsection{Capturing Instructions for Diagnosis}\hfill\\
%XXX Talk about what data we gather using lldb, the debugger in the LLVM
%compiler tool chain.
Since the output of \xxx is the nodes and user input events suspected to cause
the busy spinning, more detail may required to verify and fix the bug. After
the offline analysis on the graph, \xxx provides tools for user to exact
the backtrace events from the output and generate a script for conditional
debugging.

The debugging scripts go through the instructions of apps and frameworks step
by step to capture the parameters tained by user inputs. At each beginning of
a function call, the script records a full callstack for it. Considering the
overhead and usefullness, it steps over and only record the return value of APIs
from libraries with a filename extension .dylib.

The supplementary information are subject to the users review to pinpoint the
root cause of spinning beachball on MacOS

%%\subsection{Finding Similar Events}
%%
%%The performance isssue caused by the busy processing in UI thread is quite
%%straightforward to diagnoze with our tool. Debugging the UI thread blocking on
%%the contention of resource is much more difficult.  In this situation, our tool
%%is required to recognize the corresponding node which obtained the resource in
%%its normal execution.
%%
%%Node comparision algorithm helps to allieviate users from the burden of
%%inspecting large logs.  We first normalize the nodes with selected events.  In
%%our system, we exclude the interrupts from the comparison since the number and
%%type of interrupts are usually different from execution to exection.  For the
%%events that connected to other events, we normalize it with a peer attribute to
%%record the process id of its connecting peer, We also record the name of the
%%system calls, message id carried in mach\_msg for corresponding events.  The
%%comparison algorithm omits the repeating times of the same events, by checking
%%if one node contains all distinct events in the other node.
%%
%%The above step only idenfity the similarity of nodes.  We also define the
%%differential attribtes to distinguish the normal node and spinning node,
%%including the waiting time, execution time and system call return values.
