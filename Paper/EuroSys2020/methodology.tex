\subsection{Methodology} \label{sec:methodology}

In this section, we first describe how the performance issues are selected for
study. Then we compare \xxx to its closest prior system and describe how we
evaluate the manual efforts needed in diagnosis.

We collect performance issues in the deployed machine in daily use and search
from github bug reports with the keywords "spinning beachball". Only bug
reports from popular applications are selected since they likely represents
the bugs attractive to tech-savvy users. The performance issues that we failed
to reproduce with a week, due to the version capacity or reproducibility, are
discarded. As a result, we select 11 reproducible cases in macOS Elcapitan for
study in this paper.

%Also explain what metrics/outcomes we look for. "whether these tools enable a
%developer to identify root cause of a given performance issues" or "quantify the
%manual effort needed to ..."

Panappticon is the closest system to \xxx in desgin. We implement it in macOS
as a baseline with event types and causal relationships defined in its paper.
It depends on the resource usage analysis for each transaction to identify
the performance bottleneck and speculate the possible causes. Further manual
efforts are required to investigate the root causes. Although it is effective
in identifying performance issue due to resource contention in Android, our
implementation in macOS fails in the extraction of end-to-end transactions
for the following reasons: untracked data dependency, missing boundaries of
execution intervals in background threads, batch processing in both user threads
and system threads, and contraditions to the assumption that no unrelated work
is processed in a particular task from a queue. It is common to find two and
more user input events, even events from unrelated applications are collapsed
into a request graph.

To demonstate the effectiveness of \xxx, we enable \xxx tracing component in
the background and reproduce the performance isssue. During the event graph
construction in \xxx, we measure the number of vertexes are introduced and
merged by heuristics to mitigate the inaccuracy. Then we run \xxx diagnosis
algorithm on the graph with human in the loop. We count the times when multiple
incoming causal edges are presents and \xxx requires users' guidance in path
slicing. Users can query the event graph for assistance and make decisions with
domain knowledge. In the worst case that users make a wrong decision, before it
reaching the end of search, \xxx allows them to relocate the search path to a
particular vertex. The number presents in the table reflects our experience of
debugging. It does not include the situation of relocating the path searching
vertex, which we did not encountered in our case studies.
